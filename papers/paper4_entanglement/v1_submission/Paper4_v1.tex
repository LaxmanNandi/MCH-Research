\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{mathptmx}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{natbib}
\usepackage{fancybox}
\usepackage{setspace}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=cyan,
    pdftitle={Engagement as Entanglement: Variance Signatures of Bidirectional Context Coupling in LLMs},
    pdfauthor={Laxman M M},
}

\title{\LARGE\textbf{Engagement as Entanglement: Variance Signatures of\\Bidirectional Context Coupling in Large Language Models}}

\author{
    \textbf{Dr.\ Laxman M M, MBBS}\\
    Government Duty Medical Officer, PHC Manchi\\
    Bantwal Taluk, Dakshina Kannada, Karnataka, India\\
    DNB General Medicine Resident (2026), KC General Hospital, Bangalore\\
    Email: \texttt{barlax5377@gmail.com}\\
    ORCID: \href{https://orcid.org/0009-0009-0405-6531}{0009-0009-0405-6531}
}

\date{February 2026}

\begin{document}

\maketitle

\begin{center}
\fbox{\parbox{0.9\textwidth}{
\textbf{Paper 4 of the MCH Research Program} --- This paper provides a mechanistic framework for the $\Delta$RCI metric introduced in Papers~1--2 and applied temporally in Paper~3. We demonstrate that context sensitivity tracks variance reduction in response embeddings, introducing a Variance Reduction Index (VRI) as a practical entanglement surrogate and identifying convergent versus divergent coupling as a deployment-relevant distinction.
}}
\end{center}

\vspace{0.5em}

% ============================================
% ABSTRACT
% ============================================
\begin{abstract}
\noindent We present an entanglement framework for understanding context sensitivity in large language models.
Using embedding-level variance analysis across 12 model-domain runs (4 philosophy, 8 medical) and
360 position-level measurements, we demonstrate that $\Delta$RCI---a measure of context sensitivity
introduced in Papers~1--2---tracks variance reduction in response embeddings.
The correlation between $\Delta$RCI and the Variance Reduction Index ($\text{VRI} = 1 - \text{Var\_Ratio}$)
is strong and highly significant ($r = 0.76$, $p = 8.2 \times 10^{-69}$, $N = 360$).
This relationship reveals bidirectional context coupling: \emph{convergent entanglement}
($\text{Var\_Ratio} < 1$, $\Delta\text{RCI} > 0$), where context narrows the response distribution,
and \emph{divergent entanglement} ($\text{Var\_Ratio} > 1$, $\Delta\text{RCI} < 0$), where context widens it.
Two medical models (Llama 4 Scout: $\text{Var\_Ratio} = 7.46$; Llama 4 Maverick: $\text{Var\_Ratio} = 2.64$)
exhibit extreme divergent entanglement at the summarization position (P30), producing highly unstable
outputs when task enablement is expected. We propose Var\_Ratio as a practical, low-cost surrogate
for entanglement measurement and identify convergent versus divergent entanglement as a deployment-relevant distinction.
\end{abstract}

\vspace{0.5em}
\noindent\textbf{Keywords:} context sensitivity, $\Delta$RCI, entanglement, variance reduction, response predictability, LLM deployment safety, medical AI

% ============================================
% 1. INTRODUCTION
% ============================================
\section{Introduction}

Context sensitivity in language models---the degree to which conversational history shapes
responses---has been characterized across architectures and domains using $\Delta$RCI
\citep{laxman2026paper1, laxman2026paper2} and shown to follow task-specific temporal
patterns \citep{laxman2026paper3}. However, the \emph{mechanism} by which context shapes
responses remains empirically uncharacterized.

$\Delta$RCI captures the aggregate change in response alignment with and without context,
but does not describe how the \emph{distribution} of responses changes. A model with high
$\Delta$RCI may achieve this through narrow, predictable outputs under context, or through
a complex, high-variance coupling that pulls responses in consistent directions while
increasing individual trial variance. These represent distinct deployment profiles.

This paper introduces an entanglement framework that connects $\Delta$RCI to the variance
structure of response embeddings. The core insight is that context sensitivity can be
understood as \textbf{predictability modulation}: context changes the shape of the response
distribution, and $\Delta$RCI quantifies that change. When context narrows the distribution
(\emph{convergent entanglement}), responses become more predictable. When context widens
the distribution (\emph{divergent entanglement}), responses become less predictable.

We operationalize this framework using the Variance Reduction Index (VRI), defined as:
\begin{align}
    \text{VRI} &= 1 - \text{Var\_Ratio} \label{eq:vri}\\
    \text{Var\_Ratio} &= \frac{\text{Var}(\text{TRUE embeddings})}{\text{Var}(\text{COLD embeddings})} \label{eq:varratio}
\end{align}
where variance is computed across 50 independent trials at each conversational position.
Positive VRI indicates that context reduces variance (convergent entanglement); negative
VRI indicates that context increases variance (divergent entanglement).

The entanglement framework makes three contributions. First, it provides a mechanistic
interpretation of $\Delta$RCI as predictability modulation rather than a pure helpfulness
measure. Second, it reveals bidirectional coupling---context can either stabilize or
destabilize responses---resolving the previously unexplained ``Sovereign'' category from
Paper~1. Third, it identifies a concrete safety risk: models that exhibit extreme divergent
entanglement at task-critical positions produce unpredictable outputs when predictability
is most needed.

% ============================================
% 2. METHODS
% ============================================
\section{Methods}

\subsection{Data}

We analyze the 12-model subset from the MCH Research Program that has complete response
text preserved. Each model-domain run consists of 50 independent trials under three
conditions (TRUE, COLD, SCRAMBLED) with 30 conversational prompts per trial. All runs
used temperature = 0.7, max\_tokens = 1024, and all-MiniLM-L6-v2 embeddings
(384-dimensional) \citep{reimers2019sentence}.

\subsection{Model Set}

\textbf{Philosophy (4 models, closed/commercial):}
GPT-4o, GPT-4o-mini, Claude Haiku, Gemini Flash.

\textbf{Medical (8 models):}
DeepSeek V3.1, Kimi K2, Llama 4 Maverick, Llama 4 Scout, Mistral Small 24B,
Ministral 14B, Qwen3 235B, Gemini Flash.

\noindent This 12-model subset represents a subset of the 25 model-domain runs from
Paper~2; only runs with complete response text saved are included, as embedding-level
variance computation requires access to raw responses.

\subsection{Metrics}

\textbf{$\Delta$RCI} was computed as in Papers~1--3: per-position
$\text{mean}(\text{RCI}_{\text{TRUE}}) - \text{mean}(\text{RCI}_{\text{COLD}})$, where
RCI is the mean pairwise cosine similarity within a condition across 50 trials.

\textbf{Note on RCI\textsubscript{COLD}:} RCI\textsubscript{COLD} reflects responses to prompts
delivered with no conversational history (the COLD condition), not cross-condition
similarity. Each RCI value is computed within its own condition.

\textbf{Var\_Ratio} was computed per position as
$\text{Var}(\text{TRUE embeddings}) / \text{Var}(\text{COLD embeddings})$, where
variance is the mean variance across all 384 embedding dimensions, averaged across 50
independent trials at each prompt position.

\textbf{VRI} (Variance Reduction Index) $= 1 - \text{Var\_Ratio}$. Positive VRI indicates
context reduces variance; negative VRI indicates context increases variance.

\subsection{Statistical Analysis}

The primary test is the Pearson correlation between $\Delta$RCI and VRI across all
360 position-level measurements (12 models $\times$ 30 positions). Secondary analyses
examine domain-specific variance patterns, model-level Var\_Ratio distributions, and
the position-30 anomaly.

% ============================================
% 3. RESULTS
% ============================================
\section{Results}

\subsection{Finding 1: $\Delta$RCI tracks VRI (entanglement signal)}

Across 12 model-domain runs and 30 positions, $\Delta$RCI correlated strongly with VRI:

\begin{itemize}
    \item \textbf{Pooled correlation:} $r = 0.76$, $p = 8.2 \times 10^{-69}$ ($N = 360$ model-position points)
    \item Data: 12 model-domain runs $\times$ 30 positions $= 360$ points
    \item Each point aggregates 50 independent trials per condition
\end{itemize}

$\Delta$RCI increases as context reduces response variance. This supports the entanglement
interpretation: context couples the response distribution to prior information, changing
the predictability of outputs.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.80\textwidth]{../figures/entanglement_validation.png}
    \caption{\textbf{$\Delta$RCI vs VRI across 360 model-position points.}
    Blue: philosophy models (4). Red: medical models (8). The strong positive
    correlation ($r = 0.76$, $p = 8.2 \times 10^{-69}$) validates the entanglement
    framework: higher context sensitivity corresponds to greater variance reduction.
    Points in the lower-left quadrant represent divergent entanglement
    ($\text{Var\_Ratio} > 1$, $\Delta\text{RCI} < 0$).}
    \label{fig:entanglement}
\end{figure}

\noindent\textit{Note on scope:} Entanglement analysis requires actual response text to
compute embedding variances. Only 12 of the 25 available model-domain runs from Paper~2
have complete response text preserved. Expansion to additional models would require
rerunning experiments with response text preservation enabled.

\subsection{Finding 2: Bidirectional entanglement (convergent vs.\ divergent)}

The variance ratio reveals two distinct regimes:

\begin{itemize}
    \item \textbf{Convergent entanglement:} $\text{Var\_Ratio} < 1$, $\Delta\text{RCI} > 0$.
          Context narrows the response distribution, making outputs more predictable.
    \item \textbf{Divergent entanglement:} $\text{Var\_Ratio} > 1$, $\Delta\text{RCI} < 0$.
          Context widens the response distribution, making outputs less predictable.
\end{itemize}

This bidirectional framing resolves the ``Sovereign'' category from Paper~1: Sovereign
behavior corresponds to divergent entanglement, where context destabilizes rather than
stabilizes predictability. This is not a failure of context processing but a distinct mode of coupling.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../figures/fig4_entanglement_multipanel.png}
    \caption{\textbf{Multi-panel entanglement analysis.}
    The regime map shows convergent ($\text{Var\_Ratio} < 1$) and divergent
    ($\text{Var\_Ratio} > 1$) regions, with domain-specific patterns and
    position-dependent dynamics across medical and philosophy models.}
    \label{fig:multipanel}
\end{figure}

\subsection{Finding 3: Llama safety anomaly at medical P30}

At medical position 30 (the summarization prompt), two Llama models exhibit extreme
divergent entanglement:

\begin{itemize}
    \item \textbf{Llama 4 Maverick:} $\text{Var\_Ratio} = 2.64$, $\Delta\text{RCI} = -0.15$
    \item \textbf{Llama 4 Scout:} $\text{Var\_Ratio} = 7.46$, $\Delta\text{RCI} = -0.22$
\end{itemize}

While other open medical models (Qwen3 235B, Mistral Small 24B) show mild divergence
($\text{Var\_Ratio} = 1.02$--$1.45$), only the Llama models exhibit extreme instability
at P30. Convergent models at P30 show $\text{Var\_Ratio} < 1$ and positive $\Delta$RCI
(Kimi K2, Ministral 14B, DeepSeek V3.1, Gemini Flash).

This identifies a \textbf{safety risk class}: models that diverge under closed-goal
prompts produce highly unstable, unpredictable outputs precisely when task enablement
is expected. The clinical implications---stochastically incomplete summaries with intact
factual accuracy---are explored further in Paper~5 \citep{laxman2026paper5}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../figures/fig7_llama_safety_anomaly.png}
    \caption{\textbf{Llama safety anomaly at medical P30.}
    Divergent variance signatures ($\text{Var\_Ratio} \gg 1$) at the summarization
    position indicate extreme output instability in Llama 4 Maverick and Llama 4 Scout.
    Other open-weight medical models show mild or no divergence.
    Convergent models (Kimi K2, DeepSeek V3.1, Gemini Flash, Ministral 14B)
    show $\text{Var\_Ratio} < 1$ at P30.}
    \label{fig:llama}
\end{figure}

\subsection{Finding 4: Domain-specific variance patterns}

Mean variance ratios differ by domain:

\begin{itemize}
    \item \textbf{Philosophy:} $\text{Var\_Ratio} \approx 1.01$ (variance-neutral on average)
    \item \textbf{Medical:} $\text{Var\_Ratio} \approx 1.20$ (variance-increasing on average)
\end{itemize}

Medical prompts tend to destabilize response distributions under context, while philosophy
is largely variance-neutral. This domain difference is consistent with the conservation
constraint reported in Paper~6 \citep{laxman2026paper6}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.80\textwidth]{../figures/fig5_independence_rci_var.png}
    \caption{\textbf{RCI vs.\ Variance Ratio across models and positions.}
    Domain-specific relationship between context sensitivity and output variance.
    Medical models (red) cluster at higher Var\_Ratio than philosophy models (blue),
    indicating that closed-goal tasks systematically increase output variance under context.}
    \label{fig:independence}
\end{figure}

\subsection{Finding 5: Variance ratio as a practical entanglement surrogate}

The variance ratio provides a practical, low-cost surrogate for entanglement measurement.
$\Delta$RCI tracks VRI ($r = 0.76$) without requiring $k$-NN entropy estimation or full
mutual information computation. Computing Var\_Ratio requires only response embeddings and
basic variance calculations, making entanglement measurement accessible at scale. This
enables the deployment assessment framework developed in Paper~5.

% ============================================
% 4. DISCUSSION
% ============================================
\section{Discussion}

\subsection{Entanglement reframes $\Delta$RCI as predictability modulation}

The central conceptual shift is that $\Delta$RCI is not merely a measure of helpfulness
but a \textbf{predictability modulation} measure. Context changes the shape of the
response distribution; $\Delta$RCI quantifies that change. This reframing clarifies
why negative $\Delta$RCI values are not inherently problematic: they indicate divergent
entanglement, which may be useful for creative tasks but is concerning for
safety-critical domains.

\subsection{Bidirectional entanglement resolves the Sovereign category}

The ``Sovereign'' category from Paper~1---models whose responses became less aligned
under context---is now grounded in mechanism. Contexts that increase variance produce
negative $\Delta$RCI. This is not a failure of context usage but a distinct mode of
coupling. Divergent entanglement is a valid, measurable regime rather than a missing category.

\subsection{Safety implications: predictability is task-dependent}

The Llama divergence at medical P30 highlights a concrete risk: models can become less
predictable exactly when a task presupposes context. For safety-critical tasks,
\textbf{predictability is a requirement}, not an optional characteristic.
Divergent entanglement in these settings should be treated as a deployment risk.

We propose (as provisional guidance) that $\text{Var\_Ratio} > 3$ at critical task
positions be treated as a flag for further investigation. This threshold is empirically
motivated by the Llama anomaly but is not validated as a standard; it identifies the
range where output variance becomes clinically problematic. Calibration against patient
safety outcomes remains future work.

\subsection{Architectural interpretation}

The emergence of convergent versus divergent classes suggests differences in how models
handle context saturation at task-critical positions. This observation is consistent
across multiple models but remains \emph{descriptive} rather than causal. Future work
should test whether divergence correlates with training objectives, attention patterns,
or safety alignment strategies.

\subsection{Limitations}

\textbf{Model subset.} Only 12 of 25 model-domain runs have response text, limiting
the analysis to 360 data points. Expansion requires rerunning experiments with text
preservation.

\textbf{Embedding dependence.} Variance metrics depend on the all-MiniLM-L6-v2 embedding
space. Alternative embedding models may yield different variance ratio distributions.

\textbf{Cross-model normalization.} Models with higher baseline variance (Var\_COLD) will
naturally produce different Var\_Ratio magnitudes. We report raw values because absolute
predictability change is deployment-relevant, but normalized comparisons would be
appropriate for ranking models on relative sensitivity.

\textbf{Two domains.} This study analyzes text-only interactions in medical and philosophical
domains only. Whether the convergent/divergent distinction generalizes to other domains
(legal, creative, coding) requires further study.

\textbf{Observational scope.} Claims are matched to the experimental scope: text-only,
two-domain, 50-trial evaluation with a focused model set. Broader generalizations are
stated as hypotheses.

% ============================================
% 5. CONCLUSION
% ============================================
\section{Conclusion}

We demonstrate that context sensitivity ($\Delta$RCI) tracks variance reduction in
response embeddings (VRI), with a pooled correlation of $r = 0.76$
($p = 8.2 \times 10^{-69}$, $N = 360$). This validates an entanglement framework in
which context modulates the predictability of model outputs. The framework reveals
bidirectional coupling: convergent entanglement narrows the response distribution, while
divergent entanglement widens it.

Two Llama models exhibit extreme divergent entanglement at the medical summarization
position ($\text{Var\_Ratio}$ up to 7.46), producing unstable outputs when task
enablement is expected. This identifies a concrete safety risk class that is invisible
to aggregate performance metrics but detectable with the variance-based screening
method introduced here.

The Variance Reduction Index (VRI) provides a practical, low-cost surrogate for
entanglement measurement, enabling the deployment predictability framework developed
in Paper~5 \citep{laxman2026paper5} and the conservation constraint reported in
Paper~6 \citep{laxman2026paper6}.

% ============================================
% ACKNOWLEDGMENTS
% ============================================
\section*{Acknowledgments}

This research builds on the MCH Research Program established in Paper~1. AI systems
(Claude, ChatGPT, DeepSeek) assisted with data analysis, visualization, and manuscript
preparation. The framework, findings, and interpretations remain the author's sole
responsibility.

% ============================================
% DATA AVAILABILITY
% ============================================
\section*{Data Availability}

All raw data, response text, and analysis scripts are available in the project repository:
\url{https://github.com/LaxmanNandi/MCH-Research}

% ============================================
% REFERENCES
% ============================================
\bibliographystyle{plainnat}
\begin{thebibliography}{20}

\bibitem[Laxman, 2026a]{laxman2026paper1}
Laxman, M.\ M.\ (2026a).
\newblock Context curves behavior: Measuring AI relational dynamics with $\Delta$RCI.
\newblock {\em Preprints.org}, 202601.1881. DOI:~10.20944/preprints202601.1881.v2

\bibitem[Laxman, 2026b]{laxman2026paper2}
Laxman, M.\ M.\ (2026b).
\newblock Standardized context sensitivity benchmark across 25 LLM-domain configurations.
\newblock {\em Preprints.org}, 202602.1114. DOI:~10.20944/preprints202602.1114.v2

\bibitem[Laxman, 2026c]{laxman2026paper3}
Laxman, M.\ M.\ (2026c).
\newblock Domain-specific temporal dynamics of context sensitivity in large language models.
\newblock {\em Preprints.org}, ID:~199272.

\bibitem[Laxman, 2026d]{laxman2026paper5}
Laxman, M.\ M.\ (2026d).
\newblock Stochastic incompleteness in LLM summarization: A predictability taxonomy
for clinical AI deployment.
\newblock In preparation.

\bibitem[Laxman, 2026e]{laxman2026paper6}
Laxman, M.\ M.\ (2026e).
\newblock An empirical conservation constraint on context sensitivity and output variance:
Evidence across LLM architectures.
\newblock In preparation.

\bibitem[Brown et al., 2020]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., et al.\ (2020).
\newblock Language models are few-shot learners.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[Vaswani et al., 2017]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.\ N.,
Kaiser, \L., \& Polosukhin, I.\ (2017).
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 30.

\bibitem[Reimers \& Gurevych, 2019]{reimers2019sentence}
Reimers, N., \& Gurevych, I.\ (2019).
\newblock Sentence-BERT: Sentence embeddings using Siamese BERT-networks.
\newblock {\em Proceedings of EMNLP 2019}.

\bibitem[Asgari et al., 2025]{asgari2025framework}
Asgari, E., et al.\ (2025).
\newblock A framework to assess clinical safety and hallucination rates of LLMs
for medical text summarisation.
\newblock {\em npj Digital Medicine}, 8(1), 274.

\bibitem[Liu et al., 2024]{liu2024lost}
Liu, N.\ F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F.,
\& Liang, P.\ (2024).
\newblock Lost in the middle: How language models use long contexts.
\newblock {\em Transactions of the Association for Computational Linguistics}, 12, 104--123.

\end{thebibliography}

% ============================================
% SUPPLEMENTARY FIGURES
% ============================================
\clearpage
\appendix
\section*{Supplementary Figures}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../figures/figure6_gaussian_verification.png}
    \caption{\textbf{Figure S1: Gaussian assumption verification.}
    Distribution analysis of $\Delta$RCI values across models and positions.
    Marginal normality is partially satisfied ($|\text{skew}| < 1$, $|\text{kurt}| < 3$
    for 61--76\% of dimensions), validating the use of Pearson correlation as the primary
    statistical test. Effective dimensionality: 12--23 of 384 dimensions.}
    \label{fig:gaussian}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../figures/figure8_trial_convergence.png}
    \caption{\textbf{Figure S2: Trial-level convergence analysis.}
    $\Delta$RCI stability across 50 independent trials per model-domain run.
    Rolling 5-trial means show stable estimates throughout. Slope tests: 12/14 models
    show non-significant drift ($p > 0.05$), confirming 50-trial adequacy for stable estimation.}
    \label{fig:convergence}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../figures/figure9_model_comparison.png}
    \caption{\textbf{Figure S3: Model-level $\Delta$RCI comparison.}
    Mean $\Delta$RCI values by model with 95\% confidence intervals.
    Medical models (closed-goal): mean $\Delta$RCI $= 0.341$;
    Philosophy models (open-goal): mean $\Delta$RCI $= 0.317$.
    Bar chart illustrates inter-model variability and domain separation.}
    \label{fig:model_comparison}
\end{figure}

\end{document}
