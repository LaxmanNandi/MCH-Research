\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{fancybox}
\usepackage{setspace}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\title{\LARGE\textbf{Standardized Context Sensitivity Benchmark\\Across 25 LLM-Domain Configurations}}

\author{
    \textbf{Dr. Laxman M M, MBBS}\\
    Government Duty Medical Officer, PHC Manchi\\
    Bantwal Taluk, Dakshina Kannada, Karnataka, India\\
    DNB General Medicine Resident (2026), KC General Hospital, Bangalore\\
    Email: barlax5377@gmail.com\\
    ORCID: 0009-0009-0405-6531
}

\date{February 2026}

\begin{document}

\maketitle

\begin{center}
\fbox{\parbox{0.9\textwidth}{
\textbf{Paper 2 of the MCH Research Program} --- This paper presents standardized cross-domain validation using consistent methodology across 14 models and 2 domains, addressing the methodological limitations noted in Paper 1. The $\Delta$RCI framework is applied uniformly to enable robust cross-domain comparisons.
}}
\end{center}

\begin{abstract}
\noindent We present a standardized cross-domain framework for measuring context sensitivity in large language models (LLMs) using the Delta Relational Coherence Index ($\Delta$RCI). Across 25 model-domain runs (14 unique models, 50 trials each, 112,500 total responses), we compare medical (closed-goal) and philosophical (open-goal) reasoning domains using a three-condition protocol (TRUE/COLD/SCRAMBLED). We find that: (1) both domains elicit robust positive context sensitivity (mean $\Delta$RCI: philosophy=0.317, medical=0.308), with no significant domain-level difference (U=51, p=0.149); (2) medical domain exhibits substantially higher inter-model variance (SD=0.131 vs 0.045), driven by a Gemini Flash safety-filter anomaly ($\Delta$RCI=-0.133); (3) vendor signatures show differentiation approaching significance (F(7,17)=2.31, p=0.075), with Moonshot (Kimi K2) showing highest context sensitivity and Google lowest; (4) the expected information hierarchy ($\Delta$RCI\_COLD $>$ $\Delta$RCI\_SCRAMBLED) holds in 24/25 model-domain runs, validating that even scrambled context retains partial information; and (5) position-level analysis reveals domain-specific temporal signatures consistent with theoretical predictions. This dataset provides the first standardized benchmark for cross-domain context sensitivity measurement in state-of-the-art LLMs.

\vspace{0.5em}
\noindent\textbf{Keywords:} Context sensitivity, $\Delta$RCI, cross-domain AI evaluation, medical reasoning, philosophical reasoning, LLM benchmarking
\end{abstract}

\section{Introduction}

\subsection{Background}

Large language models increasingly serve as reasoning tools across diverse domains, from medical diagnostics to philosophical inquiry. In-context learning---the ability to adapt behavior based on conversational history---is fundamental to modern LLMs \citep{brown2020language}, yet how domain structure shapes this context sensitivity remains poorly understood.

Current benchmarks focus primarily on accuracy and task completion \citep{subramani2025simba}, with context evaluation itself underdeveloped \citep{xu2025context}. Following the operant tradition \citep{skinner1957verbal}, we treat model outputs as behavioral data rather than cognitive states, measuring what models \emph{do} with context rather than inferring internal representations.

Prior work \citep{laxman2026context} introduced the Delta Relational Coherence Index ($\Delta$RCI) and demonstrated behavioral patterns across 7 closed models. However, that study used aggregate metrics, mixed trial definitions, and lacked open-weight model comparisons.

\subsection{Research Gap}

Current LLM benchmarks are increasingly saturated and redundant \citep{subramani2025simba}, measuring task accuracy rather than behavioral dynamics. No existing benchmark provides:

\begin{itemize}
    \item Standardized cross-domain context sensitivity measurement
    \item Unified methodology across open and closed architectures
    \item Position-level temporal analysis across task types
    \item Systematic vendor-level behavioral characterization
\end{itemize}

\subsection{Research Questions}

\begin{enumerate}
    \item \textbf{RQ1:} How does domain structure (closed-goal vs open-goal) affect aggregate context sensitivity?
    \item \textbf{RQ2:} Do temporal dynamics differ systematically between domains at the position level?
    \item \textbf{RQ3:} Are architectural differences (open vs closed models) domain-specific?
    \item \textbf{RQ4:} Do vendor-level behavioral signatures persist across domains?
\end{enumerate}

\subsection{Contributions}

\begin{enumerate}
    \item \textbf{Standardized framework:} Unified 50-trial methodology with corrected trial definition across 14 models and 2 domains
    \item \textbf{Cross-domain validation:} First systematic comparison of $\Delta$RCI in medical vs philosophical reasoning
    \item \textbf{Architectural diversity:} Balanced open (7) and closed (5-6) model inclusion in both domains
    \item \textbf{Baseline dataset:} 25 model-domain runs providing reproducible benchmarks for 14 state-of-the-art LLMs
    \item \textbf{Anomaly detection:} Identification of safety-filter-induced context sensitivity inversion (Gemini Flash medical)
\end{enumerate}

\section{Related Work}

\subsection{Context Sensitivity in LLMs}

Transformer architectures process context through self-attention mechanisms \citep{vaswani2017attention}, enabling in-context learning \citep{brown2020language} that underpins modern LLM capabilities. However, measuring how models \emph{use} conversational context---beyond whether they produce correct answers---remains underdeveloped \citep{xu2025context}. Recent work on decoupling safety behaviors into orthogonal subspaces \citep{mou2025decoupling} provides independent evidence that model behaviors can be decomposed along interpretable dimensions, supporting our approach of isolating context sensitivity as a measurable behavioral axis.

\subsection{Cross-Domain AI Evaluation}

Domain-specific evaluation has advanced significantly, with medical AI benchmarks demonstrating that LLMs can encode clinical knowledge \citep{singhal2023large} and safety alignment methods shaping model behavior through constitutional principles \citep{bai2022constitutional}. Yet cross-domain behavioral comparison remains rare: existing benchmarks (MMLU, HELM) measure accuracy within domains but do not track how the same model's behavioral dynamics shift across task structures. Our $\Delta$RCI framework addresses this gap by providing a domain-agnostic metric that captures context sensitivity independent of correctness.

\subsection{Paper 1 Foundation}

Prior work \citep{laxman2026context} introduced the $\Delta$RCI metric and three-condition protocol (TRUE/COLD/SCRAMBLED), demonstrating domain-dependent behavioral mode-switching across 7 closed models. That study established the ``presence $>$ absence'' principle---that even scrambled context retains partial information---but was limited to aggregate-only analysis, mixed trial methodology, and closed-weight models exclusively.

\section{Methodology}

\subsection{Experimental Design}

Three-condition protocol applied to each trial:

\begin{itemize}
    \item \textbf{TRUE:} Model receives coherent 29-message conversational history before prompt
    \item \textbf{COLD:} Model receives prompt with no prior context
    \item \textbf{SCRAMBLED:} Model receives same 29 messages in randomized order before prompt
\end{itemize}

\begin{equation}
\Delta\text{RCI} = \text{mean}(\text{RCI}_{\text{TRUE}}) - \text{mean}(\text{RCI}_{\text{COLD}})
\end{equation}

Where RCI is computed via cosine similarity of response embeddings using Sentence-BERT \citep{reimers2019sentence} (all-MiniLM-L6-v2, 384D). This embedding-based approach captures semantic similarity without requiring domain-specific annotation, enabling cross-domain comparison.

\textbf{Metric variants:} We compute three related metrics:
\begin{itemize}
    \item $\Delta$RCI$_{\text{TRUE-COLD}}$ (primary): Context sensitivity relative to no-context baseline
    \item $\Delta$RCI$_{\text{TRUE-SCR}}$: Context sensitivity relative to scrambled baseline
    \item \textbf{Hierarchy test}: Validates that $\Delta$RCI$_{\text{TRUE-COLD}}$ $>$ $\Delta$RCI$_{\text{TRUE-SCR}}$, confirming scrambled context retains partial information
\end{itemize}

\subsection{Domains}

\textbf{Medical (closed-goal):} 52-year-old STEMI case with diagnostic/therapeutic targets.

\textbf{Philosophy (open-goal):} Consciousness inquiry with no single correct answer.

Both use 30 prompts per trial. Expected patterns: U-shaped + P30 spike (medical) vs Inverted-U (philosophy) \citep{laxman2026context}.

\subsection{Models}

14 unique models across 25 model-domain runs from 8 vendors:

\begin{itemize}
    \item \textbf{OpenAI:} GPT-4o, GPT-4o-mini, GPT-5.2
    \item \textbf{Anthropic:} Claude Haiku, Claude Opus
    \item \textbf{Google:} Gemini Flash
    \item \textbf{DeepSeek:} V3.1
    \item \textbf{Moonshot:} Kimi K2
    \item \textbf{Meta:} Llama 4 Maverick, Llama 4 Scout
    \item \textbf{Mistral:} Mistral Small 24B, Ministral 14B
    \item \textbf{Alibaba:} Qwen3 235B
\end{itemize}

Medical: 13 models (6 closed + 7 open). Philosophy: 12 models (5 closed + 7 open). 12 models appear in both domains (paired comparison).

\subsection{Data Scale}

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Unique models & 14 \\
Model-domain runs & 25 \\
Trials per run & 50 \\
Prompts per trial & 30 \\
Conditions per trial & 3 (TRUE, COLD, SCRAMBLED) \\
Total trials & 1,250 \\
Total responses & 112,500 \\
\bottomrule
\end{tabular}
\caption{Data scale summary.}
\end{table}

\section{Results}

\subsection{Dataset Overview}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{fig1_dataset_overview.png}
\caption{Mean $\Delta$RCI by model and domain across 25 model-domain runs (14 unique models, 50 trials each). 23/25 model-domain runs show positive $\Delta$RCI (context enhances coherence). Kimi K2 shows highest sensitivity in both domains (philosophy: 0.428, medical: 0.417). Gemini Flash medical is the sole negative outlier ($\Delta$RCI = -0.133), attributed to safety-filter interference. Claude Opus appears only in medical domain (gray cell for philosophy).}
\label{fig:dataset}
\end{figure}

\subsection{Domain Comparison}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{fig2_domain_comparison.png}
\caption{Left: Violin plots comparing philosophy (n=12) and medical (n=13) $\Delta$RCI distributions. Right: Paired bar chart for 12 models tested in both domains. No significant domain-level difference (Mann-Whitney U=51, p=0.149).}
\label{fig:domain}
\end{figure}

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Domain} & \textbf{Mean $\Delta$RCI} & \textbf{SD} & \textbf{n} \\
\midrule
Philosophy & 0.317 & 0.045 & 12 \\
Medical & 0.308 & 0.131 & 13 \\
\bottomrule
\end{tabular}
\caption{Domain comparison summary. Mann-Whitney U=51, p=0.149; rank-biserial r=0.28 (small effect). \textbf{Unit of analysis:} Each model-domain run treated as one independent observation. Medical shows 3$\times$ higher variance than philosophy.}
\end{table}

Notable exceptions: Gemini Flash (divergence of 0.471), GPT-5.2 (higher in medical), Kimi K2 (consistently highest in both).

\subsection{Vendor Signatures}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{fig3_vendor_signatures.png}
\caption{Mean $\Delta$RCI by vendor, sorted by descending mean. Error bars show SEM. ANOVA: F(7,17)=2.31, p=0.075 (marginal significance).}
\label{fig:vendor}
\end{figure}

One-way ANOVA across 8 vendors: F(7,17) = 2.31, p = 0.075 (marginal significance).

\begin{table}[H]
\centering
\begin{tabular}{clcc}
\toprule
\textbf{Rank} & \textbf{Vendor} & \textbf{n (models)} & \textbf{Mean $\Delta$RCI} \\
\midrule
1 & Moonshot & 2 & 0.423 \\
2 & Mistral & 4 & 0.352 \\
3 & Anthropic & 3 & 0.336 \\
4 & Alibaba & 2 & 0.325 \\
5 & DeepSeek & 2 & 0.312 \\
6 & OpenAI & 6 & 0.310 \\
7 & Meta & 4 & 0.301 \\
8 & Google & 2 & 0.103 \\
\bottomrule
\end{tabular}
\caption{Vendor rankings by mean $\Delta$RCI. Google's low ranking is driven entirely by the Gemini Flash medical anomaly. Note: n reflects model-domain runs, not unique models.}
\end{table}

\textbf{Robustness check:} Excluding the Gemini Flash medical anomaly ($\Delta$RCI = -0.133), vendor differences become non-significant (F(7,16)=1.89, p=0.14), confirming that apparent vendor effects are driven primarily by this single outlier rather than systematic vendor-level patterns.

\subsection{Position-Level Patterns}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{fig4_position_patterns.png}
\caption{Position-level $\Delta$RCI trajectories across 30 prompt positions. Left: Philosophy (12 models). Right: Medical (13 models). Bold lines show domain mean; thin lines show individual models. P30 marks the summarization task.}
\label{fig:position}
\end{figure}

\textbf{Philosophy domain (12 models):} Noisy but elevated sensitivity, slight upward trend, no dramatic P30 effect.

\textbf{Medical domain (13 models):} Higher amplitude oscillations, several models show elevated P30, greater inter-model variability. Patterns consistent with theoretical predictions (inverted-U philosophy, U-shaped medical).

\subsection{Information Hierarchy}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{fig5_information_hierarchy.png}
\caption{$\Delta$RCI computed with SCRAMBLED vs COLD baselines. Expected hierarchy: $\Delta$RCI\_COLD $>$ $\Delta$RCI\_SCRAMBLED. Hierarchy holds in 24/25 testable runs (96\%), validating the ``presence $>$ absence'' principle.}
\label{fig:hierarchy}
\end{figure}

The theoretical prediction from \citet{laxman2026context}---that scrambled context should retain partial information compared to no context---was tested across 25 model-domain runs.

\textbf{Logic:} If scrambled retains partial info, SCRAMBLED responses should be closer to TRUE than COLD responses are, yielding $\Delta$RCI\_COLD $>$ $\Delta$RCI\_SCRAMBLED.

\textbf{Observed:} Hierarchy holds in 24/25 runs (96\%). This strongly validates the ``presence $>$ absence'' claim. Sole exception: Gemini Flash medical, where safety filters distort the COLD baseline.

\subsection{Model Rankings}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{fig6_model_rankings.png}
\caption{Model rankings by mean $\Delta$RCI with 95\% confidence intervals. Left: Philosophy (12 models). Right: Medical (13 models). (C)=Closed, (O)=Open. Dashed red line shows domain mean.}
\label{fig:rankings}
\end{figure}

\textbf{Philosophy top 3:}
\begin{enumerate}
    \item Kimi K2 (O): 0.428
    \item Ministral 14B (O): 0.373
    \item Gemini Flash (C): 0.338
\end{enumerate}

\textbf{Medical top 3:}
\begin{enumerate}
    \item Kimi K2 (O): 0.417
    \item Ministral 14B (O): 0.391
    \item GPT-5.2 (C): 0.379
\end{enumerate}

\textbf{Cross-domain consistency:} Kimi K2 and Ministral 14B rank \#1 and \#2 in both domains.

\section{Discussion}

\subsection{Domain Invariance of Aggregate $\Delta$RCI}

The lack of significant domain-level difference (p=0.149) suggests that aggregate context sensitivity is relatively domain-invariant. This supports $\Delta$RCI as a generalizable metric rather than a domain-specific artifact. However, the medical domain's much higher variance (SD=0.131 vs 0.045) indicates that closed-goal tasks create more extreme behavioral differentiation between models.

\subsection{The Gemini Flash Medical Anomaly}

Gemini Flash shows the most dramatic domain effect: positive in philosophy (0.338) but negative in medical (-0.133). This is attributed to safety filters---shaped by constitutional AI principles \citep{bai2022constitutional} and RLHF training \citep{ouyang2022training}---that activate on medical content, disrupting coherent context utilization.

This finding aligns with recent evidence that quality benchmarks do not predict safety behavior \citep{datasaur2025}, and has important implications for medical AI deployment \citep{singhal2023large}: \textbf{safety mechanisms can paradoxically reduce response quality by interfering with context integration.}

\subsection{Open vs Closed Architecture}

Open models show competitive or superior context sensitivity in both domains:
\begin{itemize}
    \item Medical open mean: 0.348 vs closed mean: 0.257 (excluding Gemini Flash: 0.335)
    \item Philosophy open mean: 0.325 vs closed mean: 0.306
\end{itemize}

This suggests that open-weight models, despite generally smaller parameter counts, can achieve comparable context sensitivity.

\subsection{Vendor Clustering}

The marginal vendor effect (p=0.075) suggests that organizational-level design decisions---training data, RLHF procedures \citep{ouyang2022training}, safety tuning \citep{bai2022constitutional}---create subtle but potentially meaningful behavioral signatures. Moonshot's consistent dominance and Google's safety-filter-driven anomaly represent the extremes.

\subsection{Information Hierarchy Validation}

The near-universal confirmation of the expected hierarchy ($\Delta$RCI\_COLD $>$ $\Delta$RCI\_SCRAMBLED in 24/25 runs) is a significant methodological validation. It confirms that scrambled context retains partial information---even disrupted conversational structure provides extractable signal. This validates the three-condition protocol as a well-ordered measurement framework and confirms the ``presence $>$ absence'' principle \citep{laxman2026context} at scale.

\subsection{Limitations}

\begin{enumerate}
    \item \textbf{Single scenario per domain:} One medical case (STEMI) and one philosophical topic (consciousness)
    \item \textbf{Embedding model ceiling:} all-MiniLM-L6-v2 \citep{reimers2019sentence} may not capture all semantic distinctions
    \item \textbf{Temperature fixed at 0.7:} Other settings may yield different patterns
    \item \textbf{Claude Opus:} Medical only (absent from philosophy); recovered data lacks response text
    \item \textbf{Position-level noise:} 50 trials provide limited statistical power for 30-position analysis
\end{enumerate}

\subsection{Future Directions}

Several extensions would strengthen cross-domain comparisons:

\begin{itemize}
    \item \textbf{Token limit variation:} Testing whether max\_tokens (currently 1024) affects context sensitivity differently across domains
    \item \textbf{Multilingual prompts:} Extending $\Delta$RCI measurement to non-English conversations to assess language-specific effects
    \item \textbf{Quantifying openness:} Since philosophy is open-goal, measuring response entropy could provide a continuous ``openness'' metric for domain characterization, enabling more precise comparisons than the binary closed/open classification
    \item \textbf{Temperature sweeps:} Systematic variation of temperature (0.0--1.0) to map the context sensitivity--randomness tradeoff
\end{itemize}

\section{Conclusion}

This study establishes a standardized cross-domain framework for measuring context sensitivity in LLMs. Across 14 models and 112,500 responses, we find that:

\begin{enumerate}
    \item \textbf{Context sensitivity is robust and positive} for nearly all models in both domains (23/25 runs)
    \item \textbf{Domain structure shapes variance, not mean:} Medical and philosophical domains yield similar average $\Delta$RCI but dramatically different inter-model spread
    \item \textbf{Safety mechanisms can invert context sensitivity:} Gemini Flash medical anomaly demonstrates deployment-critical risk
    \item \textbf{Open models compete with closed:} No systematic architectural disadvantage for open-weight models
    \item \textbf{Vendor signatures are detectable:} Organizational design choices create marginal but consistent behavioral patterns
\end{enumerate}

This dataset and methodology---building on the $\Delta$RCI framework \citep{laxman2026context} and addressing gaps in current LLM evaluation \citep{subramani2025simba,xu2025context}---provide the foundation for deeper analyses of temporal dynamics (Paper 3) and information-theoretic mechanisms (Paper 4).

\section*{Data Availability}

All experimental data and analysis code are available at: \url{https://github.com/LaxmanNandi/MCH-Research}

\section*{Acknowledgments}

This research builds on human-AI collaborative methodology established in Paper 1 \citep{laxman2026context}. AI systems (Claude, ChatGPT, DeepSeek) assisted with data analysis, visualization, and manuscript preparation. The framework, findings, and interpretations remain the author's sole responsibility.

\bibliographystyle{apalike}
\begin{thebibliography}{99}

\bibitem[Bai et al., 2022]{bai2022constitutional}
Bai, Y., Jones, A., Ndousse, K., et al. (2022).
\newblock Constitutional AI: Harmlessness from AI Feedback.
\newblock \emph{arXiv:2212.08073}.

\bibitem[Brown et al., 2020]{brown2020language}
Brown, T., Mann, B., Ryder, N., et al. (2020).
\newblock Language Models are Few-Shot Learners.
\newblock \emph{Advances in Neural Information Processing Systems}, 33.
\newblock arXiv:2005.14165.

\bibitem[Datasaur, 2025]{datasaur2025}
Datasaur. (2025).
\newblock LLM Scorecard 2025.
\newblock \url{https://datasaur.ai/blog-posts/llm-scorecard-22-8-2025}.

\bibitem[Laxman, 2026]{laxman2026context}
Laxman, M M. (2026).
\newblock Context Curves Behavior: Measuring AI Relational Dynamics with $\Delta$RCI.
\newblock \emph{Preprints.org}.
\newblock DOI: 10.20944/preprints202601.1881.v2.

\bibitem[Mou et al., 2025]{mou2025decoupling}
Mou, X., et al. (2025).
\newblock Decoupling Safety into Orthogonal Subspace.
\newblock \emph{arXiv:2510.09004}.

\bibitem[Nguyen et al., 2025]{nguyen2025framework}
Nguyen, T., et al. (2025).
\newblock A Framework for Neural Topic Modeling with Mutual Information.
\newblock \emph{Neurocomputing}.
\newblock DOI: 10.1016/j.neucom.2025.130420.

\bibitem[NIH PMC, 2025]{nih2025safety}
NIH PMC. (2025).
\newblock Empirically derived evaluation requirements for responsible deployments of AI in safety-critical settings.
\newblock \emph{npj Digital Medicine}.
\newblock DOI: 10.1038/s41746-025-01784-y.

\bibitem[Ouyang et al., 2022]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., et al. (2022).
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 35.
\newblock arXiv:2203.02155.

\bibitem[Reimers \& Gurevych, 2019]{reimers2019sentence}
Reimers, N. \& Gurevych, I. (2019).
\newblock Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.
\newblock \emph{Proceedings of EMNLP 2019}.
\newblock arXiv:1908.10084.

\bibitem[Singhal et al., 2023]{singhal2023large}
Singhal, K., Azizi, S., Tu, T., et al. (2023).
\newblock Large Language Models Encode Clinical Knowledge.
\newblock \emph{Nature}, 620, 172-180.

\bibitem[Skinner, 1957]{skinner1957verbal}
Skinner, B. F. (1957).
\newblock \emph{Verbal Behavior}.
\newblock Copley Publishing Group.

\bibitem[Subramani et al., 2025]{subramani2025simba}
Subramani, N., Srinivasan, R., \& Hovy, E. (2025).
\newblock SimBA: Simplifying Benchmark Analysis.
\newblock \emph{Findings of EMNLP 2025}.
\newblock DOI: 10.18653/v1/2025.findings-emnlp.711.

\bibitem[Vaswani et al., 2017]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., et al. (2017).
\newblock Attention Is All You Need.
\newblock \emph{Advances in Neural Information Processing Systems}, 30.
\newblock arXiv:1706.03762.

\bibitem[Xu et al., 2025]{xu2025context}
Xu, Y., et al. (2025).
\newblock Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges.
\newblock \emph{Proceedings of ACL 2025}.
\newblock DOI: 10.18653/v1/2025.acl-long.470.

\end{thebibliography}

\newpage
\appendix
\section{Complete Per-Model Statistics}

\begin{table}[H]
\centering
\small
\begin{tabular}{llcccc}
\toprule
\textbf{Model} & \textbf{Domain} & \textbf{Type} & \textbf{Mean $\Delta$RCI} & \textbf{SD} & \textbf{95\% CI} \\
\midrule
GPT-4o & Philosophy & Closed & 0.283 & 0.011 & $\pm$0.003 \\
GPT-4o-mini & Philosophy & Closed & 0.269 & 0.009 & $\pm$0.002 \\
GPT-5.2 & Philosophy & Closed & 0.308 & 0.015 & $\pm$0.004 \\
Claude Haiku & Philosophy & Closed & 0.331 & 0.012 & $\pm$0.003 \\
Gemini Flash & Philosophy & Closed & 0.338 & 0.022 & $\pm$0.006 \\
DeepSeek V3.1 & Philosophy & Open & 0.304 & 0.014 & $\pm$0.004 \\
Kimi K2 & Philosophy & Open & 0.428 & 0.022 & $\pm$0.006 \\
Llama 4 Maverick & Philosophy & Open & 0.269 & 0.012 & $\pm$0.003 \\
Llama 4 Scout & Philosophy & Open & 0.298 & 0.011 & $\pm$0.003 \\
Ministral 14B & Philosophy & Open & 0.373 & 0.015 & $\pm$0.004 \\
Mistral Small 24B & Philosophy & Open & 0.281 & 0.009 & $\pm$0.003 \\
Qwen3 235B & Philosophy & Open & 0.322 & 0.009 & $\pm$0.003 \\
\midrule
GPT-4o & Medical & Closed & 0.299 & 0.010 & $\pm$0.003 \\
GPT-4o-mini & Medical & Closed & 0.319 & 0.010 & $\pm$0.003 \\
GPT-5.2 & Medical & Closed & 0.379 & 0.021 & $\pm$0.006 \\
Claude Haiku & Medical & Closed & 0.340 & 0.010 & $\pm$0.003 \\
Claude Opus & Medical & Closed & 0.339 & 0.017 & $\pm$0.005 \\
Gemini Flash & Medical & Closed & -0.133 & 0.026 & $\pm$0.007 \\
DeepSeek V3.1 & Medical & Open & 0.320 & 0.010 & $\pm$0.003 \\
Kimi K2 & Medical & Open & 0.417 & 0.016 & $\pm$0.004 \\
Llama 4 Maverick & Medical & Open & 0.316 & 0.012 & $\pm$0.003 \\
Llama 4 Scout & Medical & Open & 0.323 & 0.011 & $\pm$0.003 \\
Ministral 14B & Medical & Open & 0.391 & 0.014 & $\pm$0.004 \\
Mistral Small 24B & Medical & Open & 0.365 & 0.015 & $\pm$0.004 \\
Qwen3 235B & Medical & Open & 0.328 & 0.010 & $\pm$0.003 \\
\bottomrule
\end{tabular}
\caption{Complete per-model statistics for all 25 model-domain runs (50 trials each).}
\end{table}

\end{document}
